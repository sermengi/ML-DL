{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import tensorflow dataset\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "# use as_supervised: load tuple structure (input,target)\n",
    "# use with_info: get information about dataset\n",
    "mnist_dataset,mnist_info = tfds.load(name='mnist',with_info=True,as_supervised=True)\n",
    "\n",
    "# Train and Test split\n",
    "mnist_train,mnist_test = mnist_dataset['train'],mnist_dataset['test']\n",
    "\n",
    "# Use training dataset to create Validation set\n",
    "num_validation_samples = 0.1*mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples,tf.int64)\n",
    "\n",
    "# Create test samples\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples,tf.int64)\n",
    "\n",
    "# Scale the variables\n",
    "# define a function for scaling\n",
    "def scale(image,label):\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image /= 255.\n",
    "    return image,label\n",
    "\n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "# Shuffle the data\n",
    "# define a buffer size and shuffle the validation and training data\n",
    "BUFFER_SIZE = 10000\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "#Extract the train and validation data\n",
    "# use skip to define a training data \n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
    "\n",
    "# Set the Batch size\n",
    "BATCH_SIZE = 100\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "# Covert validation set to iterable object\n",
    "validation_inputs,validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input, output and hidden layer size\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 50\n",
    "\n",
    "# Define the model\n",
    "# flatten the input, define activation func\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(output_size,activation='softmax')\n",
    "])\n",
    "\n",
    "# choose the loss and optimizer function\n",
    "# use model.compile method\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 19s - loss: 0.4148 - accuracy: 0.8867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "540/540 - 19s - loss: 0.1911 - accuracy: 0.9441 - val_loss: 0.1689 - val_accuracy: 0.9500\n",
      "Epoch 3/5\n",
      "540/540 - 19s - loss: 0.1447 - accuracy: 0.9580 - val_loss: 0.1361 - val_accuracy: 0.9580\n",
      "Epoch 4/5\n",
      "540/540 - 19s - loss: 0.1177 - accuracy: 0.9657 - val_loss: 0.1216 - val_accuracy: 0.9615\n",
      "Epoch 5/5\n",
      "540/540 - 19s - loss: 0.1015 - accuracy: 0.9698 - val_loss: 0.0977 - val_accuracy: 0.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b0d567e48>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define number of epochs and validation steps\n",
    "NUM_EPOCHS = 5\n",
    "VALIDATION_STEPS = num_validation_samples\n",
    "\n",
    "# use model.fit method to fit model\n",
    "# specify data, epochs, add validation data  and set verbose\n",
    "model.fit(train_data,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          validation_data=(validation_inputs,validation_targets),\n",
    "          validation_steps=VALIDATION_STEPS,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - accuracy: 0.9669\n",
      "Test loss: 0.11. Test_accuracy: 0.97%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with model.evaluate() method\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print('Test loss: {0:.2f}. Test_accuracy: {1:.2f}%'.format(test_loss,test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using different Hidden Layer Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a model with hidden_layer_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 20s - loss: 0.3577 - accuracy: 0.8993 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "540/540 - 19s - loss: 0.1487 - accuracy: 0.9562 - val_loss: 0.1300 - val_accuracy: 0.9623\n",
      "Epoch 3/5\n",
      "540/540 - 20s - loss: 0.1067 - accuracy: 0.9679 - val_loss: 0.1028 - val_accuracy: 0.9693\n",
      "Epoch 4/5\n",
      "540/540 - 19s - loss: 0.0844 - accuracy: 0.9747 - val_loss: 0.0861 - val_accuracy: 0.9748\n",
      "Epoch 5/5\n",
      "540/540 - 19s - loss: 0.0696 - accuracy: 0.9787 - val_loss: 0.0723 - val_accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b06962488>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define number of epochs and validation steps\n",
    "NUM_EPOCHS = 5\n",
    "VALIDATION_STEPS = num_validation_samples\n",
    "\n",
    "# use model.fit method to fit model\n",
    "# specify data, epochs, add validation data  and set verbose\n",
    "model.fit(train_data,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          validation_data=(validation_inputs,validation_targets),\n",
    "          validation_steps=VALIDATION_STEPS,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a model with depth of hidden layer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 20s - loss: 0.3968 - accuracy: 0.8802 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "540/540 - 19s - loss: 0.1648 - accuracy: 0.9516 - val_loss: 0.1465 - val_accuracy: 0.9597\n",
      "Epoch 3/5\n",
      "540/540 - 20s - loss: 0.1257 - accuracy: 0.9623 - val_loss: 0.1163 - val_accuracy: 0.9677\n",
      "Epoch 4/5\n",
      "540/540 - 20s - loss: 0.1010 - accuracy: 0.9690 - val_loss: 0.1019 - val_accuracy: 0.9680\n",
      "Epoch 5/5\n",
      "540/540 - 20s - loss: 0.0871 - accuracy: 0.9733 - val_loss: 0.0833 - val_accuracy: 0.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b07a33ac8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set input, output and hidden layer size\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 50\n",
    "\n",
    "# Define the model\n",
    "# flatten the input, define activation func\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(output_size,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# define number of epochs and validation steps\n",
    "NUM_EPOCHS = 5\n",
    "VALIDATION_STEPS = num_validation_samples\n",
    "\n",
    "# use model.fit method to fit model\n",
    "# specify data, epochs, add validation data  and set verbose\n",
    "model.fit(train_data,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          validation_data=(validation_inputs,validation_targets),\n",
    "          validation_steps=VALIDATION_STEPS,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using different Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 20s - loss: 1.0149 - accuracy: 0.7811 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "540/540 - 19s - loss: 0.3261 - accuracy: 0.9140 - val_loss: 0.2791 - val_accuracy: 0.9223\n",
      "Epoch 3/5\n",
      "540/540 - 19s - loss: 0.2428 - accuracy: 0.9296 - val_loss: 0.2267 - val_accuracy: 0.9355\n",
      "Epoch 4/5\n",
      "540/540 - 19s - loss: 0.2006 - accuracy: 0.9420 - val_loss: 0.1939 - val_accuracy: 0.9467\n",
      "Epoch 5/5\n",
      "540/540 - 20s - loss: 0.1710 - accuracy: 0.9499 - val_loss: 0.1661 - val_accuracy: 0.9523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b084981c8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set input, output and hidden layer size\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 50\n",
    "\n",
    "# Define the model\n",
    "# flatten the input, define activation func\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='sigmoid'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='sigmoid'),\n",
    "                            tf.keras.layers.Dense(output_size,activation='softmax')\n",
    "])\n",
    "\n",
    "# choose the loss and optimizer function\n",
    "# use model.compile method\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "# define number of epochs and validation steps\n",
    "NUM_EPOCHS = 5\n",
    "VALIDATION_STEPS = num_validation_samples\n",
    "\n",
    "# use model.fit method to fit model\n",
    "# specify data, epochs, add validation data  and set verbose\n",
    "model.fit(train_data,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          validation_data=(validation_inputs,validation_targets),\n",
    "          validation_steps=VALIDATION_STEPS,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using different Activation function for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 19s - loss: 0.4069 - accuracy: 0.8897 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "540/540 - 19s - loss: 0.1702 - accuracy: 0.9497 - val_loss: 0.1430 - val_accuracy: 0.9585\n",
      "Epoch 3/5\n",
      "540/540 - 20s - loss: 0.1288 - accuracy: 0.9621 - val_loss: 0.1218 - val_accuracy: 0.9653\n",
      "Epoch 4/5\n",
      "540/540 - 19s - loss: 0.1016 - accuracy: 0.9698 - val_loss: 0.0994 - val_accuracy: 0.9717\n",
      "Epoch 5/5\n",
      "540/540 - 20s - loss: 0.0854 - accuracy: 0.9750 - val_loss: 0.0829 - val_accuracy: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b08d6e488>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set input, output and hidden layer size\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 50\n",
    "\n",
    "# Define the model\n",
    "# flatten the input, define activation func\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='tanh'),\n",
    "                            tf.keras.layers.Dense(output_size,activation='softmax')\n",
    "])\n",
    "\n",
    "# choose the loss and optimizer function\n",
    "# use model.compile method\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "# define number of epochs and validation steps\n",
    "NUM_EPOCHS = 5\n",
    "VALIDATION_STEPS = num_validation_samples\n",
    "\n",
    "# use model.fit method to fit model\n",
    "# specify data, epochs, add validation data  and set verbose\n",
    "model.fit(train_data,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          validation_data=(validation_inputs,validation_targets),\n",
    "          validation_steps=VALIDATION_STEPS,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54/54 - 19s - loss: 1.1666 - accuracy: 0.6896 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "54/54 - 18s - loss: 0.3610 - accuracy: 0.9001 - val_loss: 0.2963 - val_accuracy: 0.9172\n",
      "Epoch 3/5\n",
      "54/54 - 18s - loss: 0.2682 - accuracy: 0.9243 - val_loss: 0.2423 - val_accuracy: 0.9327\n",
      "Epoch 4/5\n",
      "54/54 - 18s - loss: 0.2276 - accuracy: 0.9367 - val_loss: 0.2135 - val_accuracy: 0.9402\n",
      "Epoch 5/5\n",
      "54/54 - 18s - loss: 0.2009 - accuracy: 0.9441 - val_loss: 0.1936 - val_accuracy: 0.9455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b09a94108>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define number of epochs and validation steps\n",
    "NUM_EPOCHS = 5\n",
    "VALIDATION_STEPS = num_validation_samples\n",
    "\n",
    "# use model.fit method to fit model\n",
    "# specify data, epochs, add validation data  and set verbose\n",
    "model.fit(train_data,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          validation_data=(validation_inputs,validation_targets),\n",
    "          validation_steps=VALIDATION_STEPS,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size 1 (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54000/54000 - 105s - loss: 0.2590 - accuracy: 0.9211 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "54000/54000 - 103s - loss: 0.1606 - accuracy: 0.9551 - val_loss: 0.1396 - val_accuracy: 0.9630\n",
      "Epoch 3/5\n",
      "54000/54000 - 103s - loss: 0.1422 - accuracy: 0.9608 - val_loss: 0.1339 - val_accuracy: 0.9643\n",
      "Epoch 4/5\n",
      "54000/54000 - 102s - loss: 0.1339 - accuracy: 0.9654 - val_loss: 0.1340 - val_accuracy: 0.9658\n",
      "Epoch 5/5\n",
      "54000/54000 - 102s - loss: 0.1288 - accuracy: 0.9675 - val_loss: 0.1386 - val_accuracy: 0.9685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b0ac24d48>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define number of epochs and validation steps\n",
    "NUM_EPOCHS = 5\n",
    "VALIDATION_STEPS = num_validation_samples\n",
    "\n",
    "# use model.fit method to fit model\n",
    "# specify data, epochs, add validation data  and set verbose\n",
    "model.fit(train_data,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          validation_data=(validation_inputs,validation_targets),\n",
    "          validation_steps=VALIDATION_STEPS,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "540/540 - 21s - loss: 1.2405 - accuracy: 0.6691 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "540/540 - 19s - loss: 0.4372 - accuracy: 0.8879 - val_loss: 0.3584 - val_accuracy: 0.9000\n",
      "Epoch 3/50\n",
      "540/540 - 20s - loss: 0.3316 - accuracy: 0.9093 - val_loss: 0.3018 - val_accuracy: 0.9147\n",
      "Epoch 4/50\n",
      "540/540 - 20s - loss: 0.2894 - accuracy: 0.9194 - val_loss: 0.2710 - val_accuracy: 0.9218\n",
      "Epoch 5/50\n",
      "540/540 - 19s - loss: 0.2662 - accuracy: 0.9254 - val_loss: 0.2502 - val_accuracy: 0.9312\n",
      "Epoch 6/50\n",
      "540/540 - 19s - loss: 0.2451 - accuracy: 0.9311 - val_loss: 0.2341 - val_accuracy: 0.9342\n",
      "Epoch 7/50\n",
      "540/540 - 19s - loss: 0.2306 - accuracy: 0.9345 - val_loss: 0.2194 - val_accuracy: 0.9373\n",
      "Epoch 8/50\n",
      "540/540 - 19s - loss: 0.2148 - accuracy: 0.9396 - val_loss: 0.2070 - val_accuracy: 0.9412\n",
      "Epoch 9/50\n",
      "540/540 - 19s - loss: 0.2023 - accuracy: 0.9432 - val_loss: 0.1962 - val_accuracy: 0.9433\n",
      "Epoch 10/50\n",
      "540/540 - 19s - loss: 0.1915 - accuracy: 0.9458 - val_loss: 0.1863 - val_accuracy: 0.9463\n",
      "Epoch 11/50\n",
      "540/540 - 19s - loss: 0.1821 - accuracy: 0.9481 - val_loss: 0.1774 - val_accuracy: 0.9487\n",
      "Epoch 12/50\n",
      "540/540 - 19s - loss: 0.1738 - accuracy: 0.9501 - val_loss: 0.1701 - val_accuracy: 0.9502\n",
      "Epoch 13/50\n",
      "540/540 - 19s - loss: 0.1643 - accuracy: 0.9533 - val_loss: 0.1638 - val_accuracy: 0.9517\n",
      "Epoch 14/50\n",
      "540/540 - 19s - loss: 0.1579 - accuracy: 0.9548 - val_loss: 0.1581 - val_accuracy: 0.9542\n",
      "Epoch 15/50\n",
      "540/540 - 19s - loss: 0.1525 - accuracy: 0.9569 - val_loss: 0.1507 - val_accuracy: 0.9558\n",
      "Epoch 16/50\n",
      "540/540 - 19s - loss: 0.1459 - accuracy: 0.9581 - val_loss: 0.1459 - val_accuracy: 0.9572\n",
      "Epoch 17/50\n",
      "540/540 - 19s - loss: 0.1397 - accuracy: 0.9603 - val_loss: 0.1412 - val_accuracy: 0.9582\n",
      "Epoch 18/50\n",
      "540/540 - 19s - loss: 0.1353 - accuracy: 0.9612 - val_loss: 0.1370 - val_accuracy: 0.9598\n",
      "Epoch 19/50\n",
      "540/540 - 19s - loss: 0.1317 - accuracy: 0.9625 - val_loss: 0.1333 - val_accuracy: 0.9605\n",
      "Epoch 20/50\n",
      "540/540 - 19s - loss: 0.1268 - accuracy: 0.9641 - val_loss: 0.1295 - val_accuracy: 0.9607\n",
      "Epoch 21/50\n",
      "540/540 - 19s - loss: 0.1228 - accuracy: 0.9650 - val_loss: 0.1276 - val_accuracy: 0.9630\n",
      "Epoch 22/50\n",
      "540/540 - 19s - loss: 0.1192 - accuracy: 0.9662 - val_loss: 0.1236 - val_accuracy: 0.9640\n",
      "Epoch 23/50\n",
      "540/540 - 19s - loss: 0.1155 - accuracy: 0.9675 - val_loss: 0.1182 - val_accuracy: 0.9647\n",
      "Epoch 24/50\n",
      "540/540 - 19s - loss: 0.1107 - accuracy: 0.9686 - val_loss: 0.1157 - val_accuracy: 0.9660\n",
      "Epoch 25/50\n",
      "540/540 - 19s - loss: 0.1098 - accuracy: 0.9686 - val_loss: 0.1135 - val_accuracy: 0.9675\n",
      "Epoch 26/50\n",
      "540/540 - 19s - loss: 0.1052 - accuracy: 0.9706 - val_loss: 0.1120 - val_accuracy: 0.9668\n",
      "Epoch 27/50\n",
      "540/540 - 20s - loss: 0.1032 - accuracy: 0.9704 - val_loss: 0.1090 - val_accuracy: 0.9685\n",
      "Epoch 28/50\n",
      "540/540 - 19s - loss: 0.0992 - accuracy: 0.9717 - val_loss: 0.1068 - val_accuracy: 0.9702\n",
      "Epoch 29/50\n",
      "540/540 - 19s - loss: 0.0978 - accuracy: 0.9725 - val_loss: 0.1042 - val_accuracy: 0.9702\n",
      "Epoch 30/50\n",
      "540/540 - 19s - loss: 0.0952 - accuracy: 0.9729 - val_loss: 0.1032 - val_accuracy: 0.9708\n",
      "Epoch 31/50\n",
      "540/540 - 19s - loss: 0.0930 - accuracy: 0.9736 - val_loss: 0.0995 - val_accuracy: 0.9715\n",
      "Epoch 32/50\n",
      "540/540 - 19s - loss: 0.0901 - accuracy: 0.9741 - val_loss: 0.0992 - val_accuracy: 0.9707\n",
      "Epoch 33/50\n",
      "540/540 - 19s - loss: 0.0879 - accuracy: 0.9750 - val_loss: 0.0975 - val_accuracy: 0.9720\n",
      "Epoch 34/50\n",
      "540/540 - 19s - loss: 0.0867 - accuracy: 0.9753 - val_loss: 0.0953 - val_accuracy: 0.9722\n",
      "Epoch 35/50\n",
      "540/540 - 19s - loss: 0.0844 - accuracy: 0.9763 - val_loss: 0.0929 - val_accuracy: 0.9732\n",
      "Epoch 36/50\n",
      "540/540 - 19s - loss: 0.0826 - accuracy: 0.9770 - val_loss: 0.0920 - val_accuracy: 0.9728\n",
      "Epoch 37/50\n",
      "540/540 - 19s - loss: 0.0803 - accuracy: 0.9771 - val_loss: 0.0916 - val_accuracy: 0.9742\n",
      "Epoch 38/50\n",
      "540/540 - 19s - loss: 0.0780 - accuracy: 0.9781 - val_loss: 0.0912 - val_accuracy: 0.9735\n",
      "Epoch 39/50\n",
      "540/540 - 19s - loss: 0.0776 - accuracy: 0.9785 - val_loss: 0.0884 - val_accuracy: 0.9758\n",
      "Epoch 40/50\n",
      "540/540 - 19s - loss: 0.0754 - accuracy: 0.9788 - val_loss: 0.0854 - val_accuracy: 0.9755\n",
      "Epoch 41/50\n",
      "540/540 - 19s - loss: 0.0746 - accuracy: 0.9788 - val_loss: 0.0864 - val_accuracy: 0.9745\n",
      "Epoch 42/50\n",
      "540/540 - 19s - loss: 0.0720 - accuracy: 0.9799 - val_loss: 0.0844 - val_accuracy: 0.9750\n",
      "Epoch 43/50\n",
      "540/540 - 19s - loss: 0.0718 - accuracy: 0.9796 - val_loss: 0.0830 - val_accuracy: 0.9762\n",
      "Epoch 44/50\n",
      "540/540 - 19s - loss: 0.0691 - accuracy: 0.9809 - val_loss: 0.0804 - val_accuracy: 0.9767\n",
      "Epoch 45/50\n",
      "540/540 - 19s - loss: 0.0678 - accuracy: 0.9810 - val_loss: 0.0794 - val_accuracy: 0.9770\n",
      "Epoch 46/50\n",
      "540/540 - 19s - loss: 0.0668 - accuracy: 0.9815 - val_loss: 0.0789 - val_accuracy: 0.9775\n",
      "Epoch 47/50\n",
      "540/540 - 19s - loss: 0.0647 - accuracy: 0.9820 - val_loss: 0.0774 - val_accuracy: 0.9780\n",
      "Epoch 48/50\n",
      "540/540 - 19s - loss: 0.0637 - accuracy: 0.9824 - val_loss: 0.0767 - val_accuracy: 0.9777\n",
      "Epoch 49/50\n",
      "540/540 - 18s - loss: 0.0626 - accuracy: 0.9830 - val_loss: 0.0757 - val_accuracy: 0.9783\n",
      "Epoch 50/50\n",
      "540/540 - 19s - loss: 0.0619 - accuracy: 0.9828 - val_loss: 0.0736 - val_accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b0c788188>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set input, output and hidden layer size\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 50\n",
    "\n",
    "# Define the model\n",
    "# flatten the input, define activation func\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(output_size,activation='softmax')\n",
    "])\n",
    "\n",
    "# choose the loss and optimizer function\n",
    "# use model.compile method\n",
    "custom_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=custom_optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "# define number of epochs and validation steps\n",
    "NUM_EPOCHS = 50\n",
    "VALIDATION_STEPS = num_validation_samples\n",
    "\n",
    "# use model.fit method to fit model\n",
    "# specify data, epochs, add validation data  and set verbose\n",
    "model.fit(train_data,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          validation_data=(validation_inputs,validation_targets),\n",
    "          validation_steps=VALIDATION_STEPS,\n",
    "          verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
